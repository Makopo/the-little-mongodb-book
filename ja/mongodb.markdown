# この本について #

## ライセンス ##
書籍「MongoDBの手引き」(原著:The Little MongoDB Book)は非営利 3.0 非移植ライセンスに基づいています。 **この本に対価を支払わないでください。**

この本の複製、配布、改変、表示は基本的に自由です。しかし、常にこの本の帰属が私、Karl Seguinにあるようにしてください。商用利用はしないでください。

ライセンスの全文は以下にあります。

<http://creativecommons.org/licenses/by-nc/3.0/legalcode>

## 著者について ##
Karl Seguin は様々なフィールドやテクノロジーで経験を積んできた開発者です。.NETとRubyに精通した開発者です。OSSのそこそこアクティブなコントリビュータであり、テクニカルライターであり、時々スピーカーもしています。MongoDB界隈では、C#のMongo DBライブラリであるNoRMのコアコントリビュータだったり、[mongly](http://openmymind.net/mongly/)というインタラクティブなチュートリアルを書いたり、[Mongo Web Admin](https://github.com/karlseguin/Mongo-Web-Admin)を作ったりしていました。趣味のゲームプログラマー向けの無料サービス[mogade.com](http://mogade.com/)は、MongoDBで動いています。

Karlのこれまでの著作は[The Little Redis Book](http://openmymind.net/2012/1/23/The-Little-Redis-Book/)です。

ブログは <http://openmymind.net> で、Twitterは[@karlseguin](http://twitter.com/karlseguin)です。

## 謝辞 ##
[Perry Neal](http://twitter.com/perryneal)から見識、精神、情熱をお借りしました。またとない協力をいただきました。感謝いたします。

## 最新版 ##
この版はAsya KamskyがMongoDB 2.6向けに改版したものです。この本の最新のソースは以下にあります。

<http://github.com/karlseguin/the-little-mongodb-book>

この日本語訳の配布ページとソースへのリンクは以下にあります。

<https://github.com/Makopo/the-little-mongodb-book/wiki>

### 日本語訳 ###

Makopoppoが日本語への翻訳を行いました。翻訳の誤りは上記日本語版ソースのIssueでお知らせください。
Twitter: [@makopo](http://twitter.com/makopo)

# 序説 #
 > この章が短いのは私の手抜きではなく、ただ単にMongoDBが学習しやすいからです。

テクノロジーは瞬く間に進化するとよく言われます。新しいテクノロジーやテクニックが次々にリリースされてきているという点では、確かにそうです。しかし、プログラマーが利用する根幹のテクノロジーは、むしろスローペースで進化する、というのが、私の持論です。人は狭い範囲の事柄を学ぶのに何年もかけることがあります。驚くほどの速さで、確立されたテクノロジーが置き換わっていきます。一晩のうちに、枯れたテクノロジーは、開発者に見向きもされなくなる危険に直面することになります。

枯れたリレーショナル・データベースに対するNoSQLテクノロジーの進化は、この急速なシフトの最たるものでしょう。ある日、Webが数個のRDBMSで動作していたと思いきや、次の日には、5個かそこらのNoSQLソリューションが価値のあるソリューションとしての地位を確立してしまう、といった感じです。

これらの変化は一晩のうちに起きると思いがちですが、現実には、受け入れられるまでに何年もかかることがあります。最初に盛り上がるのは、比較的少数の開発者や会社です。ソリューションが磨かれ、葛藤を経て、新しいテクノロジーが世に出て、それを見て、他が少しずつ試してみることになるのです。これもまた、NoSQLがその典型です。ソリューションの多くは、既存のストレージソリューションの置き換えではなく、むしろ、既存の製品でできることに付け加えて何かするためのものになっています。

一通り語り尽したところで、まずやらなければならないことは、NoSQLの意味の説明でしょう。これは漠然とした用語で、使う人によって意味が違ってきます。個人的には、データのストレージで何かするシステムのことをただ漠然と指すのに使っています。言い換えると、NoSQLは(これもまた、私にとっての、です)、必ずしも1つのシステムだけが永続化レイヤの面倒を見るわけではない、という信念です。一方、リレーショナルデータベースのベンダーは、これまで、金太郎飴的ソリューションとして自社のソフトウェアをポジショニングしようとしてきました。NoSQLは受け持つ範囲を小さくして、適材適所のツールを活用できるようにする方向に向かっています。つまり、NoSQLスタックは、リレーショナルデータベースを活用することさえあります。例えばMySQLです。しかし、システムの特定の部分の永続ルックアップ目的でRedisを組み込んだり、集中的なデータ処理目的でHadoopを組み込んだりすることもあります。ざっくり言うと、NoSQLは、代替／既存／補完のパターンやデータを管理するツール類に対してオープンで配慮があるということです。

MongoDBのどこがこの全てに当てはまるか疑問に思っているかもしれません。ドキュメント指向データベースとして、MongoDBは、より汎用的なNoSQLソリューションとなっています。リレーショナルデータベースの代替として考えるべきです。リレーショナルデータベースのように、特定の用途に特化したNoSQLソリューションと連携して活用できます。MongoDBには、利点と欠点があります。欠点のほうは、この本の後半で触れることにします。

# はじめよう #
この本の大半は、MongDBのコアの機能にフォーカスします。この関係で、MongoDBシェルを頼りにします。シェルは学習しやすく、便利な管理ツールでもありますが、皆さんのコードはMongoDBドライバを使います。

ここで、MongoDBについて最初に知っておかなければならないもの、ドライバについて説明します。MongoDBには様々な言語用の[数多くの公式ドライバ](http://docs.mongodb.org/ecosystem/drivers/)があります。これらのドライバは、お馴染みの各種データベースドライバだと思っていただければ結構です。ドライバの上に、開発者コミュニティはさらに多くの言語／フレームワーク特有のライブラリを構築してきました。例えば、[NoRM](https://github.com/atheken/NoRM)はC#のライブラリで、LINQを実装しています。[MongoMapper](https://github.com/jnunemaker/mongomapper)はRubyのライブラリで、ActiveRecordと親和性が高いものとなっています。コアのMongoDBドライバを直接使ってプログラムを作成するか、より高レベルのライブラリを使うかは、皆さんの選択次第です。あえてこう書いているのは、MongoDBが初めての方々の多くが、なぜ公式のドライバとコミュニティのライブラリが存在するのか、戸惑ってしまうからです。前者は一般にMongoDBとのコアの通信／接続性に、後者は言語やフレームワーク特有の実装にフォーカスしています。

読み進める過程で、ぜひMongoDBを実際に触ることで、私がお見せしたのを真似たり、ご自分の頭に浮かんだ疑問の解を探ったりしてみてください。MongoDBを動かすのは簡単ですので、今から数分で、準備してみましょう。

1. [公式のダウンロードページ](http://www.mongodb.org/downloads)に行き、1行目(推奨の安定バージョン)から、動作させるオペレーティングシステムに対応したバイナリを取得します。開発用途では、32ビットまたは64ビットからの選択となります。

>訳註: 上記のリンク先は、`Enterprise Server`のダウンロードページとなります。そのページで`Community Server`タブをクリックすると、本書で説明されている内容が試せるだけの機能を揃えた無料版のMongoDBをダウンロードできるページに遷移します。

2. アーカイブを展開して(どこでも結構です)、`bin`サブフォルダに進みます。まだ実行可能ファイルは何も実行しないでください。ただ、`mongod`がサーバープロセスで、`mongo`がクライアントシェルであることは知っておきましょう。これらは、これから最も多くの時間接することになる2つの実行可能ファイルです。

3. `bin`サブフォルダに`mongodb.config`という名前で新しいテキストファイルを作成します。

4. mongodb.configに1行追加します。`dbpath=PATH_TO_WHERE_YOU_WANT_TO_STORE_YOUR_DATABASE_FILES` 例えば、Windowsでは`dbpath=c:\mongodb\data`で、Linuxでは`dbpath=/var/lib/mongodb/data`のような感じです。

5. `dbpath`で指定したパスが実在するようにします。

6. mongodを、`--config /path/to/your/mongodb.config`引数を追加して起動します。

例えばWindowsユーザーの場合、ダウンロードしたファイルを`c:\mongodb\`に展開して、`c:\mongodb\data\`を作成していれば、`c:\mongodb\bin\mongodb.config`にて`dbpath=c:\mongodb\data\`と指定することになります。それから、コマンドプロンプトで`c:\mongodb\bin\mongod --config c:\mongodb\bin\mongodb.config`と指定して`mongod`を起動できるはずです。

>訳註: `mongodb.config`は2.4まで使われていたもので、2.6では`mongod.conf`にYAML記法で記述するのが通常となっています。しかし、後方互換性のために、`mongodb.config`も2.6で利用可能となっています。

`bin`フォルダをPATHに追加して、より端的にこの作業を実施できるようにしても構いません。MacOSXやLinuxユーザーは、ほぼ同じ手順でできます。変えなければならないのは、パスだけのはずです。

うまくいけば、MongoDBが起動状態になっていることでしょう。エラーが発生したら、出力を注意深く読んでください。サーバーは、何が悪かったのかとても親切に説明してくれます。

ここで、`mongo`(「d」抜き)を起動しましょう。これは、シェルを稼働中のサーバーに接続してくれるものです。`db.version()`と入力して、全てが本来あるべき動作をしているか確認します。うまくいけば、インストールしたバージョン番号が表示されるはずです。

# 第1章 - 基本 #
門出として、MongoDBとの連携の基本的なメカニズムを知っておきましょう。当然ながら、これはMongoDBを理解する上での核となるものです。ただ、MongoDBを活用できるシーンは、といった高レベルの質問に答える上での参考ともなります。

手始めに、理解する必要のある6つのシンプルな概念をご紹介します。

1. MongoDBには、`database`(データベース)という、お馴染みの概念があります(Oracleではスキーマ相当のものです)。1つのMongoDBインスタンスの中には、0以上のデータベースを保持できます。それぞれのデータベースは、外部に対しては高レベルのコンテナとして振る舞います。

2. 1つのデータベースの中には、0以上の`collection`(コレクション)を保持できます。コレクションはお馴染みの`table`(テーブル)と共通の要素が充分にありますので、これら2つは同じものと考えていただいて構いません。

3. コレクションは0以上の`document`(ドキュメント)で構成されます。これも同様に、ドキュメントは`row`(行)と考えていただいて構いません。

4. 1つのドキュメントは1以上の`field`(フィールド)で構成されます。おそらく、`column`(カラム)のようなものと考えると良いでしょう。

5. MongoDBの`index`(インデックス)は、RDBMSのそれと同じようなものです。

6. `cursor`(カーソル)は、上記の5つの概念とは毛色が違いますが、重要なもので、そして見落としがちなものです。このため、これ単独で説明するに値するものと考えています。カーソルを理解する上での肝は、ユーザがMongoDBにデータを要求すると、カーソルと呼ばれる、結果セットへのポインタを返し、それを使ってユーザが、カウントしたりスキップしたりした挙句に、実際にデータを引き抜く、といったものです。

まとめると、MongoDBは`database`(データベース)の集まりで、その中に`collection`(コレクション)があります。`collection`(コレクション)は`document`(ドキュメント)の集まりです。各`document`(ドキュメント)は`field`(フィールド)の集まりです。`collection`(コレクション)には`index`(インデックス)を付与できます。これは、検索やソートのパフォーマンスを向上させます。最後に、MongoDBからデータを取得する際には、`cursor`(カーソル)を経由して行い、実際のデータ取得は、必要になってから行います。

なぜ新しい用語(コレクション 対 テーブル、ドキュメント 対 行、フィールド 対 カラム)を使うのでしょうか？物事をより複雑にしているだけではないでしょうか？実のところ、これらの概念は、リレーショナルデータベースのそれと似てはいるものの、全く同じというわけではありません。決定的な違いは、リレーショナルデータベースは`column`(カラム)を`table`(テーブル)レベルで定義するのに対し、ドキュメント指向データベースは`field`(フィールド)を`document`(ドキュメント)レベルで定義することに、端を発します。どういうことかというと、`collection`(コレクション)の中の各`document`(ドキュメント)には、それぞれ独自の`field`(フィールド)を保持できます。つまり、`collection`(コレクション)は`table`(テーブル)に比べると無能なコンテナです。逆に、`document`(ドキュメント)は`row`(行)よりも遥かに多くの情報を保持します。

これは理解すべき重要なことではありますが、まだよく分からなくても大丈夫です。2個ほどinsert文を発行すれば、意味が分かるはずです。つまるところ、ポイントは、コレクションは、中身を気にしない(スキーマレス)ということです。フィールドは、個々のドキュメントでトラッキングされます。この挙動の利点や欠点は、後の章で説明します。

ハンズオンをしてみましょう。まだ起動していなければ、`mongod`サーバーとMongoシェルを起動しましょう。シェルはJavaScriptを実行します。いくつかのグローバルコマンドを実行できます。`help`や`exit`などです。カレントのデータベースに対して実行するコマンドは、`db`オブジェクトに対して実行することになります。`db.help()`や`db.stats()`のような感じです。特定のコレクションに対して実行するコマンドは、これからたくさん実行していきますが、`db.COLLECTION_NAME`オブジェクトに対して実行することになります。`db.unicorns.help()`や`db.unicorns.count()`のような感じです。

`db.help()`と入力しましょう。`db`オブジェクトで実行可能なコマンドの一覧が表示されます。

ここで、ちょっとした注意点です。これはJavaScriptシェルですので、メソッドをカッコ`()`なしで実行すると、メソッドが実行されずに、メソッドの本体が表示されてしまいます。なぜこんなことを言っているのかというと、最初にそれをやってしまって、`function (...){`で始まるレスポンスを受け取って、びっくりしてもらいたくないからです。例えば、`db.help`(カッコなし)と入力すると、`help`メソッドの内部実装が表示されます。

まず、グローバルの`use`ヘルパーを使って、データベースを切り替えます。それでは、`use learn`と入力しましょう。データベースがまだ実在していなくても構いません。我々が作成する最初のコレクションが、`learn`データベースも作ってくれます。これで、皆さんはデータベースの中にいますので、データベースコマンドを発行できます。`db.getCollectionNames()`のような感じです。実行すると、空の配列(`[ ]`)が取得されるはずです。コレクションはスキーマレスですので、明示的に作成する必要はありません。単に新しいコレクションにドキュメントを挿入すれば良いです。挿入するには、`insert`コマンドを使います。その際に、挿入するドキュメントを渡します。

	db.unicorns.insert({name: 'Aurora',
		gender: 'f', weight: 450})

上記の行では、`unicorns`コレクションに1個のパラメタを渡して`insert`を実行しています。内部動作としては、MongoDBは、BSONという、バイナリでシリアライズ化されたJSONフォーマットを使っています。外部仕様としては、我々はJSONを大量に使うということになります。パラメタがその典型です。ここで、`db.getCollectionNames()`を実行すると、`unicorns`コレクションが表示されるはずです。

ここで、`find`コマンドを`unicorns`に対して使って、ドキュメントの一覧を取得してみましょう。

	db.unicorns.find()

皆さんが指定したデータ以外に、`_id`フィールドがありますね。全てのドキュメントには一意の`_id`が必要です。自分で作成することもできますし、MongoDBで`ObjectID`型の値を自動生成するのに任せることもできます。大半は、MongoDBに生成してもらいたいと思うことでしょう。デフォルトでは、`_id`フィールドにインデックスが付加されます。`getIndexes`コマンドで確かめてみましょう。

	db.unicorns.getIndexes()

表示されているのは、インデックスの名前と、インデックスが作成されたデータベースやコレクションと、インデックスに含まれるフィールドです。

さて、スキーマレスコレクションの話に戻りましょう。全く別のドキュメントを`unicorns`に挿入します。このような感じです。

	db.unicorns.insert({name: 'Leto',
		gender: 'm',
		home: 'Arrakeen',
		worm: false})

そして再び、`find`を使ってドキュメントの一覧を取得します。今では少し知識がありますので、このMongoDBの興味深い挙動を取り上げます。ただ、ひょっとすると、従来の用語が適切でない理由を、皆さんは理解しかけているかもしれません。

## セレクタの学習 ##
既に説明した6つの概念以外で、上級のトピックに移る前に、皆さんが確実に押さえておく必要のある、MongoDBの実用的な側面があります。クエリセレクタです。MongoDBクエリセレクタはSQL文の`where`節のようなものです。つまり、コレクションからのドキュメントの検索、カウント、更新、削除に使います。1個のセレクタは1個のJSONオブジェクトです。もっとも単純なものは`{}`で、これは全てのドキュメントにマッチします。全ての雌のユニコーンを検索したい場合は、`{gender:'f'}`を使うことになります。

セレクタの話に入り込む前に、いくつかのデータを用意して試してみましょう。まず、これまで`unicorns`コレクションに追加したものを`db.unicorns.remove({})`で削除します。では、以下のInsert文を発行して、試行に使うデータを取得できるようにしましょう(コピー＆ペーストを推奨します)。

	db.unicorns.insert({name: 'Horny',
		dob: new Date(1992,2,13,7,47),
		loves: ['carrot','papaya'],
		weight: 600,
		gender: 'm',
		vampires: 63});
	db.unicorns.insert({name: 'Aurora',
		dob: new Date(1991, 0, 24, 13, 0),
		loves: ['carrot', 'grape'],
		weight: 450,
		gender: 'f',
		vampires: 43});
	db.unicorns.insert({name: 'Unicrom',
		dob: new Date(1973, 1, 9, 22, 10),
		loves: ['energon', 'redbull'],
		weight: 984,
		gender: 'm',
		vampires: 182});
	db.unicorns.insert({name: 'Roooooodles',
		dob: new Date(1979, 7, 18, 18, 44),
		loves: ['apple'],
		weight: 575,
		gender: 'm',
		vampires: 99});
	db.unicorns.insert({name: 'Solnara',
		dob: new Date(1985, 6, 4, 2, 1),
		loves:['apple', 'carrot',
			'chocolate'],
		weight:550,
		gender:'f',
		vampires:80});
	db.unicorns.insert({name:'Ayna',
		dob: new Date(1998, 2, 7, 8, 30),
		loves: ['strawberry', 'lemon'],
		weight: 733,
		gender: 'f',
		vampires: 40});
	db.unicorns.insert({name:'Kenny',
		dob: new Date(1997, 6, 1, 10, 42),
		loves: ['grape', 'lemon'],
		weight: 690,
		gender: 'm',
		vampires: 39});
	db.unicorns.insert({name: 'Raleigh',
		dob: new Date(2005, 4, 3, 0, 57),
		loves: ['apple', 'sugar'],
		weight: 421,
		gender: 'm',
		vampires: 2});
	db.unicorns.insert({name: 'Leia',
		dob: new Date(2001, 9, 8, 14, 53),
		loves: ['apple', 'watermelon'],
		weight: 601,
		gender: 'f',
		vampires: 33});
	db.unicorns.insert({name: 'Pilot',
		dob: new Date(1997, 2, 1, 5, 3),
		loves: ['apple', 'watermelon'],
		weight: 650,
		gender: 'm',
		vampires: 54});
	db.unicorns.insert({name: 'Nimue',
		dob: new Date(1999, 11, 20, 16, 15),
		loves: ['grape', 'carrot'],
		weight: 540,
		gender: 'f'});
	db.unicorns.insert({name: 'Dunx',
		dob: new Date(1976, 6, 18, 18, 18),
		loves: ['grape', 'watermelon'],
		weight: 704,
		gender: 'm',
		vampires: 165});

これでデータが入りましたので、セレクタの学習ができます。`{field: value}`は、任意のドキュメントの中から`field`が`value`と同じであるものを検索するのに使います。`{field1: value1, field2: value2}`は、`and`文相当です。`$lt`、`$lte`、`$gt`、`$gte`、`$ne`は特別で、未満、以下、より大きい、以上、異なる値、という演算子です。例えば、700ポンドより重い全ての雄のユニコーンを取得するには、こうします。

	db.unicorns.find({gender: 'm',
		weight: {$gt: 700}})
	// こちらでも良い (厳密には異なるが、デモ用途)
	db.unicorns.find({gender: {$ne: 'f'},
		weight: {$gte: 701}})


`$exists`演算子はフィールドの存在有無のマッチに使います。例を示します。

	db.unicorns.find({
		vampires: {$exists: false}})

は、1つのドキュメントだけ返すはずです。`$in`演算子は配列で渡す複数の値のどれかへのマッチに使います。例を示します。

    db.unicorns.find({
    	loves: {$in:['apple','orange']}})

これは'apple'または'orange'が好きなユニコーンを返します。

複数のフィールドの複数の条件で、ANDではなくORを使いたい場合は、`$or`演算子を使って、ORで繋げたいセレクタの配列にその演算子をアサインします。

	db.unicorns.find({gender: 'f',
		$or: [{loves: 'apple'},
			  {weight: {$lt: 500}}]})

上記は、全ての雌のユニコーンのうち、リンゴが好きか、500ポンド未満のものを返します。

最後の2つの例では、とても凝ったことが起きています。既にお気づきかもしれませんが、`loves`フィールドは配列です。MongoDBは第一級オブジェクトとして配列をサポートしています。これは非常に便利な特性です。いったん使い始めると、無い間は一体どうやって過ごしていたのかと不思議に思うことになります。何より興味深いのは、配列の値に基づいて抽出するのがどれほど簡単か、ということです。`{loves: 'watermelon'}`は`watermelon`が`loves`の値となっているあらゆるドキュメントを返します。

これまで紹介したもの以外にも、利用可能な演算子があります。これらは全て、MongoDBマニュアルの[Query Selectors](http://docs.mongodb.org/manual/reference/operator/query/#query-selectors)セクションで説明されています。ただ、これまでに説明してきたものは、始めるにあたって基礎となるものです。ほとんどの時間で使うことになるものでもあります。

セレクタが`find`コマンドと一緒にどのように使われるかを見てきました。セレクタは、先に少し紹介した`remove`コマンドでも使えます。`count`コマンドでも使えます。こちらはまだ紹介していませんが、おそらく皆さんは発見しているかと思います。`update`コマンドでも使えます。こちらは後で時間を割いて説明します。

MongoDBが`_id`フィールド向けに生成した`ObjectId`は、このように抽出できます。

	db.unicorns.find(
		{_id: ObjectId("オブジェクトID")})

## 章のまとめ ##
`update`コマンドや`find`でできる素敵なことは、まだ説明していません。ただ、MongoDBを起動して、`insert`や`remove`コマンドを簡単に説明してきました(説明した以上の内容はありません)。`find`を紹介して、MongoDBの`selector`(セレクタ)の概要を説明しました。良いスタートを切って、これからに向けて、しっかりとした基礎を築いてきました。信じがたいでしょうが、皆さんは、MongoDBを始めるにあたって知っておく必要があることのほぼ全てを現に知っています。実はMongoDBは、早く習得でき、簡単に利用できることを目指したものなのです。次に進む前に、ローカルで色々試してみることを強くお勧めします。様々なドキュメントを、可能であれば新しいコレクションに挿入して、様々なセレクタに慣れ親しみましょう。`find`、`count`、`remove`を使ってみましょう。自分で何回かトライすると、最初に違和感を覚えていたことが、きっと、すんなり入ってくるようになります。

# 第2章 - 更新 #
1章で、4つのCRUD(create、read、update、delete)のうちの3つを紹介しました。この章では、スキップした1つ、`update`の説明に特化します。`update`にはびっくりするような挙動がありますので、独立した章としました。

## 更新: 置換 対 $set ##
もっともシンプルな形では、`update`は2つのパラメタを取ります。セレクタ(where)と、フィールドへの更新内容です。Roooooodlesがちょっと太ってしまったら、このように実行したいと思うでしょう。

	db.unicorns.update({name: 'Roooooodles'},
		{weight: 590})

(もし`unicorns`コレクションで実験していて元のデータが無くなっていたら、全てのドキュメントを`remove`してから第1章のコードで再挿入してください。)

これで、更新されたレコードを見ると、

	db.unicorns.find({name: 'Roooooodles'})

`update`についてまず驚くことを発見することでしょう。ドキュメントは見つかりません。2番目のパラメタには、更新演算子を一切入れていませんでしたので、元のドキュメントを**置き換える**のに使われてしまったからです。どういうことかというと、`update`は`name`でドキュメントを見つけて、ドキュメント全体を新しいドキュメント(2番目のパラメタ)で置き換えてしまったのです。SQLの`update`コマンドには、そのような機能はありません。シチュエーションによっては、これは理想的な挙動で、真に動的な更新を行うのに活用されることがあります。しかし、1個や数個のフィールドの値を変更したい場合は、MongoDBの`$set`演算子を使わなければなりません。では、以下の更新を行って、失ったフィールドをリセットしましょう。

	db.unicorns.update({weight: 590}, {$set: {
		name: 'Roooooodles',
		dob: new Date(1979, 7, 18, 18, 44),
		loves: ['apple'],
		gender: 'm',
		vampires: 99}})

上記は新しい`weight`をオーバーライドしません。指定しなかったからです。ここで、以下を実行すると、

	db.unicorns.find({name: 'Roooooodles'})

期待した結果が得られます。結局のところ、最初の状態で体重を更新する正しい方法は、以下となります。

	db.unicorns.update({name: 'Roooooodles'},
		{$set: {weight: 590}})

## 更新演算子 ##
`$set`以外にも、他の演算子を利用してかっこいいことができます。全ての更新演算子はフィールドに対して働きます。つまり、ドキュメント全体がすっからかんになることはありません。例えば、`$inc`演算子はフィールドを正または負の数だけインクリメントするのに使われます。Pilotが2匹の吸血鬼を殺害したことに間違ってなってしまっていたら、以下を実行して間違いを正せます。

	db.unicorns.update({name: 'Pilot'},
		{$inc: {vampires: -2}})

Auroraが突然甘党になってしまったら、`$push`演算子で`loves`フィールドに値を追加できます。

	db.unicorns.update({name: 'Aurora'},
		{$push: {loves: 'sugar'}})

MongoDBマニュアルの[Update Operators](http://docs.mongodb.org/manual/reference/operator/update/#update-operators)セクションに、その他の利用可能な更新演算子の情報が載っています。

## UPSERT ##
`update`の利用でさらに驚くべきことの中に、`upsert`のサポートがあります。`upsert`は、見つかればドキュメントを更新して、見つからなければドキュメントを挿入するものです。UPSERTは特定のシチュエーションでは便利で、見つかれば知らせてくれます。UPSERTを有効にするには、updateに3番目のパラメタ`{upsert:true}`を渡します。

よくある例は、Webサイトの訪問カウンタです。リアルタイムの集計カウントをつけたい場合、ページに対応するレコードが既にあるか確認して、それに基づいてupdateとinsertのどちらを実行するか判断しなければなりません。UPSERTオプションが省略(またはfalseに設定)されていると、以下を実行しても、何も起きません。

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}});
	db.hits.find();

しかし、UPSERTオプションを付加すると、結果がだいぶ変わります。

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}}, {upsert:true});
	db.hits.find();

`unicorn`と一致した`page`フィールドをもつドキュメントがありませんので、新しいドキュメントが挿入されます。２回目の実行では、既存のドキュメントが更新されて、`hits`は2にインクリメントされます。

	db.hits.update({page: 'unicorns'},
		{$inc: {hits: 1}}, {upsert:true});
	db.hits.find();

## 複数更新 ##
最後に`update`がもたらす驚きは、デフォルトでは、ドキュメントを1つだけ更新するということです。これまでのところ、説明した例の範囲では、これは理にかなっていると思うかもしれません。しかし、以下のように実行した場合、

	db.unicorns.update({},
		{$set: {vaccinated: true }});
	db.unicorns.find({vaccinated: true});

全ての貴重なユニコーンが予防接種の対象として出てきてほしいでしょう。期待した挙動とするには、`multi`オプションをtrueに設定しなければなりません。

	db.unicorns.update({},
		{$set: {vaccinated: true }},
		{multi:true});
	db.unicorns.find({vaccinated: true});

## 章のまとめ ##
この章で、コレクションに対して利用可能な、基本的なCRUD操作の紹介を終えました。`update`を詳細に説明し、3つの興味深い挙動を観察しました。まず、更新演算子を入れずにドキュメントを渡すと、MongoDBの`update`は既存のドキュメントを置き換えます。このため、通常は`$set`演算子(または、ドキュメントを更新する利用可能な他のたくさんの演算子のうちの1つ)を使うことになります。次に、`update`は直感的な`upsert`オプションをサポートしており、ドキュメントが既に存在しているか不明な場合に特に役立ちます。最後に、デフォルトでは、`update`は最初にマッチしたドキュメントだけ更新しますので、マッチしたドキュメントを全て更新したい場合は、`multi`オプションを使います。

# 第3章 - Findの学習 #
1章で、`find`コマンドをざっくりと紹介しました。しかし、`selector`の理解以外にも`find`について知っておきたいことがあります。`find`の結果が`cursor`であることは既に説明しました。これが意味するところを、これから詳細に突っ込んで説明します。

## フィールドの選択 ##
`cursor`に入る前に、`find`が、「射影(projection)」と呼ばれる、2番目の任意パラメタをとることに留意してください。このパラメタは、取得または実行したいフィールドのリストです。例えば、以下を実行すると、他のフィールドを取得することなく、全てのユニコーンの名前を取得できます。

	db.unicorns.find({}, {name: 1});

デフォルトでは、`_id`フィールドは常に返されます。`{name:1, _id: 0}`と指定すると、明示的に除外できます。

`_id`フィールド以外は、包含と排他を混ぜることはできません。考えてみれば、実は道理にかなっています。皆さんは、明示的に1つ以上のフィールドを選択したいか、除外したいかのどちらかでしょう。

## 順序 ##
これまでに何度か、`find`はカーソルを返して、必要になった時までデータの取得はしないと説明してきました。しかし、シェルで`find`が即時実行されるのを間違いなく目にしてきたと思います。これはシェルだけの挙動です。`cursor`の真の挙動を、`find`に連結できるメソッドの一つを確認することで観察してみましょう。まず見るのは`sort`です。JSONドキュメントでソートしたいフィールドを指定します。昇順は1で、降順は-1を指定します。例を示します。

	//もっとも体重の重いユニコーンが先頭
	db.unicorns.find().sort({weight: -1})

	//ユニコーンの名前、吸血鬼の殺害数
	db.unicorns.find().sort({name: 1,
		vampires: -1})

リレーショナルデータベースのように、MongoDBはソートにインデックスを使用します。インデックスについては、後で詳細に説明します。ただ、インデックスがない場合、MongoDBがソートのサイズを制限することに留意してください。つまり、インデックスの使えない大きな結果セットでソートをしようとすると、エラーとなります。人によっては、これを制約と捉えています。本音では、最適化されていないクエリの実行を拒否できるデータベースがもっとあってもいいのに、と私は思っています。(MongoDBのあらゆる欠点を肯定的に考えるつもりはありませんが、データベースにstrictモードがあればいいのにと心から願うほど、最適化が下手なデータベースをたくさん見てきました。)

## ページング ##
ページングの結果は`limit`と`skip`カーソルメソッドで取得できます。2番目と3番目に体重が重いユニコーンを取得するには、以下のようにします。

	db.unicorns.find()
		.sort({weight: -1})
		.limit(2)
		.skip(1)

`sort`と一緒に`limit`を使うと、インデックスが貼られていないフィールドのソートにまつわる問題を避けられます。

## カウント ##
シェルを使うと、`count`をコレクションに対して直接実行できます。以下のような感じです。

	db.unicorns.count({vampires: {$gt: 50}})

実際には、`count`の実体は`cursor`メソッドで、シェルはショートカットを提供しているだけです。このようなショートカットがないドライバでは、以下のように実行する必要があります(以下はシェルでも動作します)

	db.unicorns.find({vampires: {$gt: 50}})
		.count()

## 章のまとめ ##
`find`と`cursor`を使うのは、わかりやすくてお薦めです。後の章で説明するか、特殊なケースでしか使わないコマンドが他にいくつかありますが、ここまでで皆さんは、Mongoシェルでの作業にしっかり慣れて、MongoDBの基礎を理解した状態になっているはずです。

# 第4章 - データモデリング #
ギアを切り替えて、MongoDBのさらに抽象的な話をしましょう。いくばくかの新しい用語と新しい構文を説明するのは、朝飯前です。モデリングにまつわる話を、新しいパラダイムを交えてするのは、そう簡単にはいきません。実際のところ、我々のほとんどが、この新しいテクノロジーでモデリングとなると、何がうまくいって何がうまくいかないか、今でも手探り状態なのです。これから話はしますが、最終的には、皆さんは現実のコードで経験を積んでいかなければなりません。

全てのNoSQLデータベースの中で、ドキュメント指向データベースはおそらくもっともリレーショナルデータベースに似ています。少なくとも、モデリングに関しては、です。しかし、存在する違いは重要です。

## Joinがない ##
最初で最大の、皆さんが慣れるべき根本的な違いは、MongoDBにはJoinがないことです。MongoDBでJoin構文のようなものがない具体的な理由を、私は知りません。しかし、Joinは一般にスケーラブルではないと考えられていることは知っています。つまり、いったんデータを水平に分割しだすと、何らかの形で、クライアント(またはアプリケーションサーバー)で連結処理をする羽目になります。理由はどうあれ、データがリレーショナル「である」ということには変わりがなく、MongoDBはJoinをサポートをしていません。

他を知ることなく、Joinなしの世界に住まうには、アプリケーションコードの中で自分で連結しなければなりません。本来、2番目のコレクションの中から関連するデータを`find`する2個目のクエリを発行する必要があります。データを準備するのは、リレーショナルデータベースで外部キーを宣言するのと何ら変わりはありません。美しい`unicorns`から少し離れて、`employees`に取り組みましょう。まずやることは、従業員の作成です(`_id`を明示的に指定して、コヒーレントなサンプルを構築できるようにしています)

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d730"),
		name: 'Leto'})

では、従業員を何人か追加して、彼らの上司を`Leto`に設定しましょう。

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d731"),
		name: 'Duncan',
		manager: ObjectId(
		"4d85c7039ab0fd70a117d730")});
	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d732"),
		name: 'Moneo',
		manager: ObjectId(
		"4d85c7039ab0fd70a117d730")});


(繰り返しますが、`_id`は一意であれば何でも結構です。実務では`ObjectId`を使うでしょうから、ここでもこれを使います。)

もちろん、Letoの従業員を全て検索するには、1行実行するだけです。

	db.employees.find({manager: ObjectId(
		"4d85c7039ab0fd70a117d730")})

ここに魔法のようなものはありません。最悪の場合、ほとんど、Joinの欠如による影響は、単に余分な(おそらくインデックス化された)クエリが必要となるだけです。

## 配列と埋め込みドキュメント ##
MongoDBにはJoinがないというだけで、秘策がないわけではありません。MongoDBが配列をドキュメントの第一級オブジェクトとしてサポートしていると説明したのを覚えていますか？これは結果として、多対１や多対多の関係を操作するのに驚くほど便利なものです。単純な例として、従業員に2人の上司がつく可能性がある場合は、配列に格納するだけで結構です。

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d733"),
		name: 'Siona',
		manager: [ObjectId(
		"4d85c7039ab0fd70a117d730"),
		ObjectId(
		"4d85c7039ab0fd70a117d732")] })

特に興味深いのは、一部のドキュメントで`manager`をスカラー値にしつつ、他のドキュメントでは配列にできることです。元々の`find`クエリは両方に対してうまく動作します。

	db.employees.find({manager: ObjectId(
		"4d85c7039ab0fd70a117d730")})

値の配列は、多対多のテーブル結合よりもはるかに手軽に扱えることが、すぐにわかるでしょう。

配列以外に、MongoDBは埋め込みドキュメントもサポートしています。ネストしたドキュメントをもつドキュメントを挿入してみましょう。このような感じです。

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d734"),
		name: 'Ghanima',
		family: {mother: 'Chani',
			father: 'Paul',
			brother: ObjectId(
		"4d85c7039ab0fd70a117d730")}})

念のために説明しておくと、埋め込みドキュメントはドット記法で検索できます。

	db.employees.find({
		'family.mother': 'Chani'})

埋め込みドキュメントが適する場所や、使いこなし方を、あとで簡単に説明します。

2つのコンセプトを合わせて、ドキュメントの配列を埋め込むこともできます。

	db.employees.insert({_id: ObjectId(
		"4d85c7039ab0fd70a117d735"),
		name: 'Chani',
		family: [ {relation:'mother',name: 'Chani'},
			{relation:'father',name: 'Paul'},
			{relation:'brother', name: 'Duncan'}]})


## 非正規化 ##
Joinの代わりの手段にはさらに、データの非正規化があります。これまで、非正規化はパフォーマンスに影響のあるコードや、データのスナップショットを取る必要がある場合(監査ログなど)に適用されてきました。しかし、NoSQLの人気上昇に伴い、多くのNoSQLにJoinがなく、通常のモデリングの一環としての非正規化が普及してきました。だからといって、あらゆるドキュメントの情報をなんでもかんでも複製すべきだということにはなりません。しかし、データを複製してしまう恐怖に駆られながら設計するよりも、どの情報がどのドキュメントに属するかに基づいてデータのモデリングを検討しましょう。

例えば、掲示板アプリケーションを作っているとします。従来の方法で特定の`user`に`post`を関連づけるには、`posts`に含まれる`userid`カラムを介します。このようなモデルでは、`users`を取得(結合)しない限り`posts`を表示できません。代替の方法として、単純に`name`と`userid`を各`post`に格納してしまうことが考えられます。埋め込みドキュメントでもできます。`user: {id: ObjectId('Something'), name: 'Leto'}`のような感じです。そうです。ユーザーが自身の名前を変更できるようにするのであれば、それぞれのドキュメントを更新しなければならないでしょう(1回の複数更新)。

この手のアプローチに適合させるのは、並大抵ではありません。多くの場合、やる意味さえないです。ただ、このアプローチに尻込みしないようにしましょう。状況によっては適しているどころか、最適な方法ということもあります。

## どちらを選択すれば良いか？ ##
１対多や多対多のシナリオを扱う際に、IDの配列は便利な戦術となります。しかしもっと一般に、埋め込みドキュメントを使うか、手動で参照するかで、新しい開発者は岐路に立たされます。

まず、現在、個々のドキュメントは16メガバイトにサイズが制限されていることに留意してください。ドキュメントにサイズ制限がある、ただ非常に緩いですが、その前提で考えると、どう使われるものなのか、察しがつくことでしょう。現時点では、ほとんどの開発者が、ほとんどの関連の参照を手動でがっつり実装している状態と思われます。埋め込みドキュメントは頻繁に活用されますが、たいていの場合、常に親ドキュメントと一緒に取得したい小規模なデータです。実世界を例にすると、`addresses`ドキュメントを各ユーザーに格納する、といったものです。以下のような感じです。

	db.users.insert({name: 'leto',
		email: 'leto@dune.gov',
		addresses: [{street: "229 W. 43rd St",
		            city: "New York", state:"NY",zip:"10036"},
		           {street: "555 University",
		            city: "Palo Alto", state:"CA",zip:"94107"}]})

だからといって、埋め込みドキュメントを過小評価したり、マイナーなユーティリティの一種だと決めつけたりしてはいけません。データモデルをオブジェクトに直接マップさせることで、ものごとがとてもシンプルになり、多くの場合、結合の必要がなくなります。MongoDBで、埋め込みドキュメントや配列のフィールドにクエリを発行したりインデックス化したりできるということを考えると、これは特に頷けます。

## 少数／多数のコレクション ##
コレクションはスキーマという枠で規制しませんので、1つのコレクションにドキュメントをごちゃ混ぜに突っ込んだシステムを構築するのも、全く可能です。しかし、それは良くない発想です。ほとんどのMongoDBシステムは、リレーショナルシステムとよく似た形で、しかし少なめのコレクションで、構築されています。言い換えると、リレーショナルデータベースのテーブルであれば、MongoDBのコレクションとなりえます(多対多の結合テーブルは重大な例外で、単純なエンティティで、１対多の関係のためだけに存在するようなテーブルも同様です)。

この話は、埋め込みドキュメントを考慮すると、さらに興味深いものになります。よく挙げられる例は、ブログです。`posts`コレクションと`comments`コレクションを持つべきか、それとも`post`のそれぞれに`comments`を埋め込ませるか？しばらく16MBドキュメントサイズ制限を脇に置くと(「ハムレット」の全文は200KBより小さいです。で、皆さんのブログはどのぐらい有名ですか？)、たいていの開発者は分けたいと思うようです。すっきりしていて、パフォーマンスも良く、曖昧さがなくなります。MongoDBのフレキシブルなスキーマでは、2つのアプローチを併用できます。専用のコレクションにコメントを格納しながら、ブログ投稿のいくつかのコメント(おそらく、最初の数個)を埋め込んで、投稿と一緒に表示できるようにできます。これは、1つのクエリで取得したいデータを一緒にしておくという原則に則っています。

難しいルールはありません(16MB以外は)。色々なアプローチを試してみましょう。何がふさわしくて、何がふさわしくないかの感覚をつかめるはずです。

## 章のまとめ ##
この章のゴールは、MongoDBでデータをモデリングするための有益なガイドラインを提供することでした。いわば取っ掛かりのようなものです。ドキュメント指向システムでのモデリングは、リレーショナルの世界とは勝手が違いますが、違いすぎるということもないです。より多くの柔軟性と1つの制約がありますが、新しいシステムには、とてもうまく適合する傾向にあります。失敗する唯一の方法は、挑戦しないことです。

# 第5章 - MongoDBの使い所 #
ここまでで、MongoDBが皆さんの既存のシステムにどのようにフィットするか、感覚が掴めたかと思います。競合するストレージテクノロジーがたくさん出現してきていますので、選択肢に埋もれがちです。

私が得た、もっとも重要な教訓は、これはMongoDBには関係ないですが、データ処理で単一のソリューションに頼らなくても良いということです。間違いなく、単一のソリューションは明白なアドバンテージがあり、多くのプロジェクトにとって、ほとんどと言っていいほど、単一のソリューションは賢明なアプローチとなります。この思想は異なるテクノロジーを使わな「ければならない」というものではなく、使っ「てもいい」というものです。新しいソリューションを導入する利点がコストを上回るかは、皆さんだけが分かることです。

そうは言うものの、皆さんはきっと、これまでの内容で、MongoDBが汎用的なソリューションだと考えるようになったことでしょう。これまで何回か、ドキュメント指向データベースはリレーショナルデータベースと共通の部分がたくさんあると言ってきました。ですので、回りくどい言い方はよして、MongoDBはリレーショナルデータベースの直接の代替として考えるべきだと言ってしまいましょう。Luceneがリレーショナルデータベースに完全なテキストインデックスをつけて拡張したものとされるのであれば、Redisが永続のkey-valueストアとされるのであれば、MongoDBはデータの中央リポジトリです。

MongoDBがリレーショナルデータベースの「置き換え」とは言っておらず、「代替」と言っていることに注意してください。これは、他のあまたのツールができることができるツールです。MongoDBが得意なこともあれば、MongoDBが不得意なこともあります。もう少し分解して見ていきましょう。

## フレキシブルなスキーマ ##
よく宣伝されているドキュメント指向データベースの利点は、固定のスキーマを押し付けられないということです。これにより、従来のデータベーステーブルよりもはるかにフレキシブルになります。フレキシブルなスキーマが素晴らしい特性であるのには同意しますが、大部分の人が挙げる主な理由からではありません。

巷の人は、スキーマレスを、まるで突然データのごった煮を格納し始めるかのように言います。リレーショナルデータベースを使ってモデリングするのが本当に苦痛となるような領域やデータセットはあるのですが、これは特別なケースだと思っています。スキーマレスはかっこいいですが、ほとんどのデータはしっかりと構造化されることになります。確かに、たまにごった煮化するのは、特に新しい機能を導入する際には便利です。しかし実際には、Null許容のカラムとは似ても似つかぬもので、おそらく同じ感覚では扱えないでしょう。

私にとっての動的スキーマの真の利点は、準備が不要で、オブジェクト指向プログラミングとの軋轢が軽減されることです。これは静的言語で作業している際に特に当てはまります。MongoDBをC#とRubyの両方で使ったことがあるのですが、違いは顕著でした。Rubyのダイナミズムとよく使われるActiveRecord実装が、既に、オブジェクトとリレーショナルの間のインピーダンスミスマッチの大部分を取り払ってくれています。だからと言って、MongoDBがRubyと相性が悪いとは言いません。実際には相性がいいです。むしろ、Ruby開発者の大半がMongoDBをインクリメンタルな進化と捉える一方で、C#やJava開発者はデータとの連携のあり方を根本的に変えるものとして捉えるだろうと、私は考えています。

ドライバ開発者の立場で考えてみましょう。オブジェクトを保存したいですか？JSON(技術的にはBSONですが、だいたい一緒)にシリアライズしてMongoDBに送りましょう。プロパティマッピングや型マッピングはありません。この簡素さは確実に皆さん、エンド開発者が享受できます。

## 書き込み ##
MongoDBがとてもよく適合する領域は、ロギングにあります。MongoDBには書き込みを非常に高速にする2つの側面があります。1つは、WRITEコマンドを送信したらすぐに復帰して、書き込みが認識されるまで待たなくて良いようにするオプションが使えることです。もう1つは、データ持続性に応じてWRITEの挙動をコントロールできることです。これらの設定は、何台のサーバがデータを受け取れば成功とみなすかという指定に追加する形で、WRITEごとに設定でき、書き込みのパフォーマンスとデータ持続性を高度にコントロールできます。

これらのパフォーマンス要因もありますが、さらに、ログデータはスキーマレスコレクションの利点をしばしば享受するデータセットの一つとなります。最後に、MongoDBには[Capped Collection](http://docs.mongodb.org/manual/core/capped-collections/)と呼ばれるものがあります。今のところ、我々が作成してきた、暗黙作成のコレクションは全て、単なる通常のコレクションです。Capped Collectionは、`db.createCollection`コマンドでcappedと指定すると作成できます。

	//Capped Collectionを1メガバイトに制限
	db.createCollection('logs', {capped: true,
		size: 1048576})

Capped Collectionが1MB制限に達すると、古いドキュメントは自動的にパージされます。ドキュメント数での制限を`max`で設定できます。サイズでの制限ではありません。Capped Collectionには興味深いプロパティがあります。例えば、ドキュメントの更新はできるが、サイズの変更はできない、などです。挿入順は維持されますので、時間ベースのソートを適切に行うためにインデックスを追加する必要はありません。Capped Collectionを「tail」できます。Unixのファイルをtailするのと同じように、`tail -f <filename>`とします。これで、再クエリすることなく新しいデータを順次受け取ることができます。

コレクションサイズではなく、時間ベースでデータを「期限切れ」にしたい場合は、[TTLインデックス](http://docs.mongodb.org/manual/tutorial/expire-data/)を検討しましょう。TTLは、「time-to-live」の略です。

## 持続性 ##
バージョン1.8までは、MongoDBにはシングルサーバーでの持続性がありませんでした。つまり、サーバーがクラッシュすると、データの消失または破壊の恐れがありました。解決策は常に、MongoDBをマルチサーバー構成で稼働させることでした(MongoDBはレプリケーションをサポートしています)。ジャーナリングは、1.8で追加された主要な機能の1つです。バージョン2.0からは、MongoDBはデフォルトでジャーナリングを有効化するようになりました。これで、クラッシュや電源断の際に、サーバーを迅速復旧できるようになっています。

持続性はここだけで説明します。MongoDBが以前はシングルサーバーでの持続性がなかったために、様々なものが作り出されていたからです。しばらくは、Google検索にその手の記事がヒットするでしょう。皆さんが目にする情報で、ジャーナリングがないことについて語っているものは、もう時代遅れです。

## 全文テキスト検索 ##
全文テキスト検索機能は、最近のMongoDBで追加されたものです。15言語で、ステミングとストップワードがサポートされています。MongoDBの配列サポートと全文テキスト検索で、パワフルで高機能な全文テキスト検索エンジンが必要な場合だけ、他のソリューションを検討すれば良いようになりました。

## トランザクション ##
MongoDBにはトランザクションがありません。2つの代替策があります。1つはとても良いですが使い道が限られ、もう1つは扱いづらいですが融通がききます。

最初のは、アトミックな更新操作です。実際に問題の解決になっていれば、これはとても良いです。`$inc`や`$set`のように、シンプルなものは、既にいくつか紹介しました。`findAndModify`コマンドというものもあります。こちらは、ドキュメントを更新または削除して、アトミックに返します。

次のは、アトミック操作では対応しきれない場合の対策として、2フェーズコミットです。2フェーズコミットとは、Joinの際の手動での参照解除を、トランザクションに読み替えたようなものです。ストレージ非依存型のソリューションで、コードで実現します。2フェーズコミットは、複数のデータベース間でトランザクションを実装する方法として、リレーショナルの世界ではお馴染みのものです。MongoDBのウェブサイトに、典型的な例(資金の移動)を説明した[サンプルがあります](http://docs.mongodb.org/manual/tutorial/perform-two-phase-commits/)。よくある着想は、アトミックに更新されるドキュメントの実体にトランザクションの状態を格納して、初期化、保留、コミット／ロールバックの手番を手動で実施する、といったものです。

MongoDBのネストしたドキュメントのサポートとフレキシブルなスキーマデザインにより、2フェーズコミットが若干楽になりますが、とても良い過程というわけではありません。最初の頃は特にです。

## データ処理 ##
バージョン2.2より前は、MongoDBはMapReduceにデータ処理ジョブを依存していました。2.2現在では、[Aggregation Pipeline (Aggregation Framework)](http://docs.mongodb.org/manual/core/aggregation-pipeline/)という強力な機能が追加されています。このため、MapReduceは、Pipelineでサポートされていないような複雑な集計関数が必要なレアなケースでしか必要としなくなりました。次章で、Aggregation PipelineとMapReduceを詳しく説明します。今の所は、(控えめに言って)`group by`する高機能な別の方法とでも思っていてください。非常に大規模なデータの並列処理には、Hadoopなど、他を検討する必要があります。ありがたいことに、2つのシステムは互いに補完するものですので、[MongoDB Connector for Hadoop](http://docs.mongodb.org/ecosystem/tools/hadoop/)というものが存在します。

もちろん、並列データ処理はリレーショナルデータベースが圧倒的に有利というわけではありません。MongoDBの将来のバージョンで、非常に大規模な一連のデータをより上手に処理できるようにするという計画があります。

## 地理空間 ##
MongoDBの特筆すべき機能は、[地理空間(Geospatial)インデックス](http://docs.mongodb.org/manual/applications/geospatial-indexes/)のサポートです。GeoJSONまたはXY座標をドキュメントに格納して、座標の`$near`(近く)や箱または円の`$within`(中)のドキュメントを検索することができます。これは視覚的に説明するのがわかりやすい機能ですので、もっと知りたい場合は、「5 Minute Geospatial Interactive Tutorial」を試してみてください。

> 訳註: 2018年1月現在、openmymind.netドメインは廃止されているため、リンクを外しました。

## ツールと成熟性 ##
既にご存じとは思いますが、MongoDBは、大半のリレーショナルデータベースシステムと比較して、明らかに年数の浅いプロジェクトです。これは絶対に考慮に入れなければならないことですが、どのぐらい重要視するかは、業務とやり方によって異なります。それでも、率直な評価として、MongoDBが年数が浅く、利用可能なツールがそれほど良くない(たくさんの成熟しきったリレーショナルデータベースで使われているツールもひどいですが！)ということは無視できません。例えば、10進浮動小数点数がサポートされない点は、(必ずしも採用見送りとはならないにしても)通貨を扱うシステムでは明らかに問題となるでしょう。

良い点としては、ドライバがたくさんの言語で存在していること、プロトコルがモダンでシンプルなこと、猛烈に開発が行われていることです。MongoDB は成熟性を気にする多くの企業の本番環境で動作しています。現状では成熟していませんが、すぐに過去のものとなるでしょう。

## 章のまとめ ##
この章で言いたかったことは、MongoDBは、多くのケースで、リレーショナルデータベースを置き換えることができるということです。よりシンプルで、単純です。より高速で、一般に、アプリケーション開発者に課す制約がより少ないです。トランザクションの欠如はもっともで深刻な問題です。しかし、巷の人に「新しいデータストレージのランドスケープのどこにMongoDBは位置するのか？」と聞かれたら、この答えはシンプルです。**ど真ん中です**。

# 第6章 - データの集計 #

## Aggregation Pipeline ##
Aggregation Pipelineを使うと、コレクションの中のドキュメントを変形したり、結合したりできます。ドキュメントをパイプラインに渡します。Unixの「パイプ」のようなものです。パイプラインで、別のコマンドや、別製品などに出力を送信します。

皆さんがおそらくお馴染みの、もっとも単純なAggregationは、SQLの`group by`表現です。単純な`count()`メソッドは既に説明しました。ただ、何匹のユニコーンが雄で何匹が雌か知りたいときは、どうしたら良いのでしょう？

	db.unicorns.aggregate([{$group:{_id:'$gender',
		total: {$sum:1}}}])

シェルには`aggregate`ヘルパーがあり、パイプライン演算子の配列を引数にとります。何かでグループ化されたものを単純に数えるには、このような演算子が1つだけ必要で、それは`$group`というものです。これはSQLの`GROUP BY`をまさに連想させるものです。新しいドキュメントを作成して、`_id`フィールドでグループ化対象のフィールドを指定します(ここでは`gender`)。もう1つのフィールドには、通常、集計の結果が入ります。この場合は、特定の性別にマッチした各ドキュメントにつき1を`$sum`(合計)します。お気づきかもしれませんが、`_id`には`'gender'`ではなく、`'$gender'`が指定されています。フィールド名の前の`'$'`は、入力ドキュメントのフィールドの値が置換される、ということを示しています。

他に利用可能なパイプライン演算子は何でしょうか？`$group`の前(しばしば後)に使われるもっとも一般的なものは、`$match`でしょう。これは`find`メソッドと同等で、ドキュメントのマッチしたサブセットだけを集計したり、もしくは一部のドキュメントを結果から除外したりできるようにするものです。

	db.unicorns.aggregate([{$match: {weight:{$lt:600}}},
		{$group: {_id:'$gender',  total:{$sum:1},
		  avgVamp:{$avg:'$vampires'}}},
		{$sort:{avgVamp:-1}} ])

ここで、もう1つのパイプライン演算子である`$sort`を紹介しましょう。これは皆さんが予想した通りのもので、`$skip`や`$limit`もできます。`$group`演算子の`$avg`はもう使いました。

MongoDB配列はパワフルで、中に格納されている値は何でも集計できてしまいます。全部をちゃんと数えるには、「フラット化」が必要です。

	db.unicorns.aggregate([{$unwind:'$loves'},
     	{$group: {_id:'$loves',  total:{$sum:1},
	 	unicorns:{$addToSet:'$name'}}},
	  	{$sort:{total:-1}},
	  	{$limit:1} ])

これで、一番多くのユニコーンに好かれている食べ物がわかり、それを好むユニコーンの名前の一覧も取得できます。`$sort`と`$limit`の組み合わせで、「Top N」系の質問の回答を出せます。

強力なパイプライン演算子には他に、[`$project`](http://docs.mongodb.org/manual/reference/operator/aggregation/project/#pipe._S_project)というものがあります(`find`で指定した射影のようなもの)。これは、特定のフィールドを挿入できるだけでなく、既存のフィールドの値を基にした新しいフィールドの作成や計算もできるものです。例えば、算術演算子で複数のフィールドの値を足し合わせて平均を算出したり、文字列演算子で既存のフィールドの文字列を連結して新しいフィールドを作成したりできます。

これはAggregationでできることをかすったに過ぎません。2.6で、Aggregationはもっと強力になりました。aggregateコマンドから、結果セットに対するカーソル(使い方は第1章で学習済み)を返すか、`$out`パイプライン演算子で新しいコレクションに結果セットを書き込むかを、選べるようになったからです。さらに多くのサンプルや、サポートされるパイプラインや正規表現演算子のあらゆる説明は、[MongoDBマニュアル](http://docs.mongodb.org/manual/core/aggregation-pipeline/)にあります。

## MapReduce ##
MapReduceはデータ処理の2段階アプローチです。まずmapを行い、次にreduceを行います。マッピング工程では、入力されたドキュメントを変形して、Key-Valueペアを送出します(keyやvalueは複雑になることがあります)。その後、Key-Valueペアはkeyでグループ化されます。同じkeyのvalueは配列化されるなどします。reduceはkeyと、keyに対応するものとして送出されたvalueの配列を受け取り、最終的な結果を生成します。mapとreduceの関数はJavaScriptで実装されています。

MongoDBではコレクションで`mapReduce`コマンドを使います。`mapReduce`はmap関数と、reduce関数と、出力ディレクティブを引数にとります。シェルで、ユーザがJavaScript関数を作成して渡します。ほとんどのライブラリでは、関数の文字列表記(少し見た目が悪いですが)を渡します。3番目のパラメタは追加のオプションを設定するもので、例えば分析したいドキュメントをフィルタしたり、ソートしたり、制限したりできます。`finalize`メソッドを渡して`reduce`工程の後で結果に適用することもできます。

ほとんどの集計において、MapReduceは使用する必要はないでしょう。しかし、もし必要があれば、「私のブログ」や[MongoDBマニュアル](http://docs.mongodb.org/manual/core/map-reduce/)で詳細を確認すると良いでしょう。

> 訳註: 2018年1月現在、openmymind.netドメインは廃止されているため、一部のリンクを外しました。

## 章のまとめ ##
この章で、MongoDBの[Aggregation機能](http://docs.mongodb.org/manual/aggregation/)を説明しました。Aggregation Pipelineは、構造を理解してしまえば比較的実装しやすいもので、データをグループ化する強力な方法となります。MapReduceは理解が難しいですが、JavaScriptで実装できる限り、できることは無限大です。

# 第7章 - パフォーマンスとツール #
この最終章で、いくつかのパフォーマンスのトピックを取り上げると共に、MongoDB開発者が利用可能なツールの一部を紹介します。どちらのトピックにも深入りしませんが、それぞれのトピックのもっとも重大な事項を詳細に説明していきます。

## インデックス ##
最初の頃に、`getIndexes`コマンドで、コレクションにある全てのインデックスの情報を確認しました。MongoDBのインデックスは、リレーショナルデータベースのインデックスと非常に似た挙動となります。クエリやソートのパフォーマンスを向上させる手助けとなります。インデックスは`ensureIndex`で作成されます。

	// "name" はフィールドの名前
	db.unicorns.ensureIndex({name: 1});

そして、`dropIndex`で削除されます。

	db.unicorns.dropIndex({name: 1});

一意のインデックスは、2番目のパラメタで`unique`を`true`と指定して作成できます。

	db.unicorns.ensureIndex({name: 1},
		{unique: true});

インデックスは、(これも、ドット記述子を使って)埋め込みフィールドにも、配列フィールドにも作成できます。複合インデックスも作成できます。

	db.unicorns.ensureIndex({name: 1,
		vampires: -1});

インデックスの方向(昇順は1、降順は-1)は、単一キーのインデックスでは関係ありませんが、複合インデックスで、複数のインデックス化されたフィールドをソートする際には、差が生じることがあります。

[Indexesのページ](http://docs.mongodb.org/manual/indexes/)にインデックスに関する詳細情報があります。

## 実行計画の取得 ##
クエリがインデックスを使っているか確認するには、カーソルに対して`explain`メソッドを使います。

	db.unicorns.find().explain()

`BasicCursor`が使用されていること(インデックス不使用)、12個のオブジェクトがスキャンされたこと、処理にかかった時間、(あれば)使用されたインデックスなどの他、いくらかの役に立つ情報が出力されます。

インデックスが使用されるようにクエリを変更すると、`BtreeCursor`が使用されている旨と、リクエストを処理するのに使用されたインデックスが表示されます。

	db.unicorns.find({name: 'Pilot'}).explain()

>訳註: 上記は2.Xの結果です。3.Xでは`explain`の結果は大幅に変更されました。3.Xでは、`stage`に`COLLSCAN`と書かれていればインデックス不使用、`IXSCAN`と書かれていればインデックス使用の検索となっています。3.Xでの出力内容の説明は、MongoDBマニュアルの[Explain Results](https://docs.mongodb.com/manual/reference/explain-results/)を参照してください。

## レプリケーション ##
MongoDBのレプリケーションは、リレーショナルデータベースのレプリケーションの仕組みと同じような仕組みとなっています。全ての本番デプロイメントはレプリカセットとしなければなりません。レプリカセットは、同じデータを保管するサーバーが3つ以上となるように構成するのが理想です。WRITEはシングルサーバー、プライマリに送られ、そこから非同期で全てのセカンダリにレプリケートされます。READがセカンダリで発生してもいいかどうかをユーザーで制御できます。これは、特殊なクエリをプライマリに発行されることを防止できる一方で、少し古いデータを読んでしまうリスクがあります。プライマリが停止すると、セカンダリのうちの1つが自動的に選出されて、新しいプライマリになります。MongoDBレプリケーションは、この本で取り扱う範囲を超えています。

## シャーディング ##
MongoDBは自動シャーディングをサポートしています。シャーディングはスケーラビリティに対するアプローチで、データをパーティション化して複数のサーバーやクラスタに分散するものです。単純に実装すると、AからMで始まる名前のユーザに関する全てのデータをサーバー1に格納して、その他をサーバー2に格納する、といった感じになるでしょう。ありがたいことに、MongoDBのシャーディング機能は、そのような単純なアルゴリズムよりもずっと優れたものとなっています。シャーディングはこの本で取り扱う範囲をかなり超えたトピックですが、機能が存在するということと、単一のレプリカセットに収まらない要件となった場合は検討すべきだということは認識しておいてください。

レプリケーションはパフォーマンス向上にいくぶん(長時間実行しているクエリをセカンダリに隔離し、他の種類のクエリのレイテンシを軽減するという意味で)寄与しますが、主な目的は高可用性です。シャーディングはMongoDBクラスタをスケーリングする上で、第一に検討すべき方法です。レプリケーションとシャーディングを併用するのは、スケーリングと高可用性の定石です。

## 統計情報 ##
データベースの統計情報を`db.stats()`とタイプして取得できます。情報のほとんどがデータベースのサイズに関するものです。コレクションの統計情報も取得できます。例えば`unicorns`の場合、`db.unicorns.stats()`とタイプします。この情報のほとんどは、コレクションのサイズとインデックスに関するものです。

## プロファイラ ##
以下を実行して、MongoDBプロファイラを有効化します。

	db.setProfilingLevel(2);

有効化された状態で、コマンドを実行します。

	db.unicorns.find({weight: {$gt: 600}});

そしてプロファイラを確認します。

	db.system.profile.find()

実行した内容と時刻、スキャンされたドキュメントの数、返却されたデータの量が表示されます。

パラメタを`0`に変更して`setProfilingLevel`を再び実行すると、プロファイラを無効化できます。最初のパラメタに`1`を指定すると100ミリ秒を超えて実行されたクエリのプロファイルが表示されます。100ミリ秒はデフォルトの閾値です。2番目のパラメタで、これとは異なる最小時間をミリ秒単位で指定できます。

	//1秒以上かかったものをプロファイリングする
	db.setProfilingLevel(1, 1000);

## バックアップ・リストア ##
MongoDBの`bin`フォルダに、`mongodump`実行可能ファイルがあります。`mongodump`を単純に実行すると、ローカルホストに接続して全てのデータベースのバックアップを`dump`サブフォルダに取得します。`mongodump --help`とタイプすると、追加のオプションを確認できます。よく使われるオプションは特定のデータベースをバックアップする`--db DBNAME`と、特定のコレクションをバックアップする`--collection COLLECTIONNAME`です。それから、`mongorestore`実行可能ファイルを使って、これは`bin`フォルダにあるのですが、以前作成したバックアップからリストアできます。これも、`--db`と`--collection`で、特定のデータベースやコレクションをリストアできます。`mongodump`と`mongorestore`はBSONを扱います。これはMongoDBのネイティブな形式です。

例えば、`learn`データベースを`backup`フォルダにバックアップする場合、このように実行します(これはコマンド／ターミナルウィンドウで実行する実行可能ファイルで、Mongoシェルの中で実行するものではありません)

	mongodump --db learn --out backup

`unicorns`コレクションだけをリストアする場合、このようにします。

	mongorestore --db learn --collection unicorns \
		backup/learn/unicorns.bson

ちなみに、`mongoexport`と`mongoimport`は、JSONまたはCSVにエクスポートとインポートをするのに使われる実行可能ファイルです。例えば、JSON出力を得るには、こうします。

	mongoexport --db learn --collection unicorns

そして、CSV出力を得るには、こうします。

	mongoexport --db learn \
		--collection unicorns \
		--csv --fields name,weight,vampires

`mongoexport`と`mongoimport`は必ずしもデータをありのままに出力するわけではありません。`mongodump`と`mongorestore`だけを、実際のバックアップに使うようにしてください。詳細は、MongoDBマニュアルの[MongoDB Backup Methods](http://docs.mongodb.org/manual/core/backups/)を参照してください。

## 章のまとめ ##
この章では、MongoDBを使う上での、様々なコマンドやツールやパフォーマンスの詳細を説明しました。まだ全てに触れていませんが、よく使うものの一部を紹介しました。MongoDBのインデックスはリレーショナルデータベースのインデックスに似ています。多くのツールもそうです。しかし、MongoDBでは、これらの多くが要領を得ていて、使いやすいものとなっています。

# 結論 #
実際のプロジェクトでMongoDBを使い始めるにあたって必要な知識は、既に身についているはずです。MongoDBには、本書で説明していない要素がもっとありますが、皆さんが次にやるべきことは、学んだことを実践し、これから使うドライバに慣れ親しむことです。[MongoDBウェブサイト](http://www.mongodb.org/)には有用な情報がたくさんあります。公式の[MongoDBユーザーグループ](http://groups.google.com/group/mongodb-user)は質問するのに最適な場所です。

NoSQLは必要に迫られて誕生しましたが、新しいアプローチを試す好奇心が生んだものでもあります。我々の業界は常に進化を遂げていますので、挑戦して、時々失敗しなければ、成功することはできません。これが、私が考える、職業人生を歩む良い方法です。